{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e232905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile service.py\n",
    "import bentoml\n",
    "\n",
    "from bentoml.io import Text, JSON\n",
    "from transformers import pipeline\n",
    "\n",
    "class PretrainedModelRunnable(bentoml.Runnable):\n",
    "    SUPPORTED_RESOURCES = (\"cpu\",)\n",
    "    SUPPORTS_CPU_MULTI_THREADING = True\n",
    "\n",
    "    def __init__(self):\n",
    "        self.classifier = pipeline(task=\"text-classification\", model='GroNLP/hateBERT')\n",
    "\n",
    "    @bentoml.Runnable.method(batchable=False)\n",
    "    def __call__(self, input_text):\n",
    "        return self.classifier(input_text)\n",
    "\n",
    "runner = bentoml.Runner(PretrainedModelRunnable, name=\"pretrained_unmasker\")\n",
    "\n",
    "svc = bentoml.Service('pretrained_classification_service', runners=[runner])\n",
    "\n",
    "@svc.api(input=Text(), output=JSON())\n",
    "async def detectViolence(input_series: str) -> list:\n",
    "    return await runner.async_run(input_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad296a47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-20T13:23:29-0600 [INFO] [cli] Prometheus metrics for HTTP BentoServer from \"service.py:svc\" can be accessed at http://localhost:3000/metrics.\n",
      "2023-03-20T13:23:30-0600 [INFO] [cli] Starting development HTTP BentoServer from \"service.py:svc\" listening on http://0.0.0.0:3000 (Press CTRL+C to quit)\n",
      "2023-03-20 13:23:30 circus[50230] [INFO] Loading the plugin...\n",
      "2023-03-20 13:23:30 circus[50230] [INFO] Endpoint: 'tcp://127.0.0.1:60393'\n",
      "2023-03-20 13:23:30 circus[50230] [INFO] Pub/sub: 'tcp://127.0.0.1:60394'\n",
      "2023-03-20T13:23:30-0600 [INFO] [observer] Watching directories: ['/Users/li/OMSA/FullStackDL/BentoML/huggingface_deployment', '/Users/li/bentoml/models']\n",
      "Some weights of the model checkpoint at GroNLP/hateBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-03-20T13:23:42-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60401 (scheme=http,method=GET,path=/,type=,length=) (status=200,type=text/html; charset=utf-8,length=2859) 0.763ms (trace=8cbd01929261b386529815d3ea483480,span=12f1a486cb6cb49d,sampled=0)\n",
      "2023-03-20T13:23:42-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60403 (scheme=http,method=GET,path=/static_content/index.css,type=,length=) (status=304,type=,length=) 8.779ms (trace=0b32c74595c16f2970a409ce88d00e70,span=53093744b993dd7b,sampled=0)\n",
      "2023-03-20T13:23:42-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60405 (scheme=http,method=GET,path=/static_content/swagger-initializer.js,type=,length=) (status=304,type=,length=) 8.895ms (trace=afd0848adf5a2e02ac7aa9c268605c4b,span=4346c3b269b64343,sampled=0)\n",
      "2023-03-20T13:23:42-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60401 (scheme=http,method=GET,path=/static_content/swagger-ui.css,type=,length=) (status=200,type=text/css; charset=utf-8,length=143980) 31.818ms (trace=42c352c37891ac4e02cc8cd258c26cca,span=8fc3fca1264efd65,sampled=0)\n",
      "2023-03-20T13:23:42-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60404 (scheme=http,method=GET,path=/static_content/swagger-ui-standalone-preset.js,type=,length=) (status=200,type=application/javascript,length=339540) 16.853ms (trace=0cc490a844cfef6db57da9f9a880ce09,span=9478701b8d337fd4,sampled=0)\n",
      "2023-03-20T13:23:42-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60402 (scheme=http,method=GET,path=/static_content/swagger-ui-bundle.js,type=,length=) (status=200,type=application/javascript,length=1096221) 28.667ms (trace=24f857139b5fdee3686e00e9277c7bf4,span=d74408e00e838aa4,sampled=0)\n",
      "2023-03-20T13:23:42-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60402 (scheme=http,method=GET,path=/docs.json,type=,length=) (status=200,type=application/json,length=4632) 25.023ms (trace=306fbaca625e8a3bece5b5eab2fe3eeb,span=1c617e34eb1ea99c,sampled=0)\n",
      "2023-03-20T13:23:57-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60415 (scheme=http,method=POST,path=/detectViolence,type=text/plain,length=7) (status=200,type=application/json,length=48) 81.442ms (trace=7c71e29b83c10856e4028e0e91e2b54e,span=47759d39a5deda92,sampled=0)\n",
      "2023-03-20T13:25:08-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60443 (scheme=http,method=POST,path=/detectViolence,type=text/plain,length=22) (status=200,type=application/json,length=48) 91.135ms (trace=dd5acd13946952e0dddab67c33b0cb45,span=dede84f05961d42c,sampled=0)\n",
      "2023-03-20T13:25:15-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60445 (scheme=http,method=POST,path=/detectViolence,type=text/plain,length=13) (status=200,type=application/json,length=48) 68.344ms (trace=4c68f034f1b9a55c28e0a8e496038fb9,span=d3b2ecf8233d8288,sampled=0)\n",
      "2023-03-20T13:25:27-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60450 (scheme=http,method=POST,path=/detectViolence,type=text/plain,length=8) (status=200,type=application/json,length=48) 71.077ms (trace=41d487c45e612be12da4b62f06af7f91,span=5e54973d02a8fba1,sampled=0)\n",
      "2023-03-20T13:25:40-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60456 (scheme=http,method=POST,path=/detectViolence,type=text/plain,length=16) (status=200,type=application/json,length=48) 74.101ms (trace=4dffb9de27ac0041d873e2524bbbca4c,span=c57a66794415e814,sampled=0)\n",
      "2023-03-20T13:25:49-0600 [INFO] [dev_api_server:pretrained_classification_service] 127.0.0.1:60460 (scheme=http,method=POST,path=/detectViolence,type=text/plain,length=2) (status=200,type=application/json,length=48) 75.161ms (trace=12ce8d42cbc0f7f9e2537bd406491569,span=4df1d7bb26e36b6f,sampled=0)\n",
      "^C\n",
      "2023-03-20T13:58:06-0600 [ERROR] [cli] Exception in callback <bound method Arbiter.manage_watchers of <circus.arbiter.Arbiter object at 0x1822a5250>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/li/miniconda3/envs/bentoml/lib/python3.9/site-packages/tornado/ioloop.py\", line 921, in _run\n",
      "    val = self.callback()\n",
      "  File \"/Users/li/miniconda3/envs/bentoml/lib/python3.9/site-packages/circus/util.py\", line 1038, in wrapper\n",
      "    raise ConflictError(\"arbiter is already running %s command\"\n",
      "circus.exc.ConflictError: arbiter is already running arbiter_stop command\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve service.py:svc --reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe6cec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bentofile.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile bentofile.yaml\n",
    "service: \"service.py:svc\"\n",
    "labels:\n",
    "include:\n",
    "- \"*.py\"\n",
    "python:\n",
    "  packages:\n",
    "  - transformers\n",
    "  - torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0cdb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building BentoML service \"pretrained_classification_service:2qgvurwfjojwv6wa\" from build context \"/Users/li/OMSA/FullStackDL/BentoML/huggingface_deployment\".\n",
      "Locking PyPI package versions.\n",
      "/Users/li/miniconda3/envs/bentoml/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "██████╗░███████╗███╗░░██╗████████╗░█████╗░███╗░░░███╗██╗░░░░░\n",
      "██╔══██╗██╔════╝████╗░██║╚══██╔══╝██╔══██╗████╗░████║██║░░░░░\n",
      "██████╦╝█████╗░░██╔██╗██║░░░██║░░░██║░░██║██╔████╔██║██║░░░░░\n",
      "██╔══██╗██╔══╝░░██║╚████║░░░██║░░░██║░░██║██║╚██╔╝██║██║░░░░░\n",
      "██████╦╝███████╗██║░╚███║░░░██║░░░╚█████╔╝██║░╚═╝░██║███████╗\n",
      "╚═════╝░╚══════╝╚═╝░░╚══╝░░░╚═╝░░░░╚════╝░╚═╝░░░░░╚═╝╚══════╝\n",
      "\n",
      "Successfully built Bento(tag=\"pretrained_classification_service:2qgvurwfjojwv6wa\").\n"
     ]
    }
   ],
   "source": [
    "!bentoml build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bacd39d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-25T18:49:18-0600 [INFO] [cli] Environ for worker 0: set CPU thread count to 10\n",
      "2023-03-25T18:49:18-0600 [INFO] [cli] Prometheus metrics for HTTP BentoServer from \"pretrained_classification_service:latest\" can be accessed at http://localhost:3000/metrics.\n",
      "2023-03-25T18:49:19-0600 [INFO] [cli] Starting production HTTP BentoServer from \"pretrained_classification_service:latest\" listening on http://0.0.0.0:3000 (Press CTRL+C to quit)\n",
      "Some weights of the model checkpoint at GroNLP/hateBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/hateBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-03-25T18:49:40-0600 [INFO] [api_server:pretrained_classification_service:7] 127.0.0.1:51439 (scheme=http,method=GET,path=/,type=,length=) (status=200,type=text/html; charset=utf-8,length=2859) 0.742ms (trace=5e10b715cc65617597426738022f2767,span=429182a4e67fb77d,sampled=0)\n",
      "2023-03-25T18:49:40-0600 [INFO] [api_server:pretrained_classification_service:7] 127.0.0.1:51439 (scheme=http,method=GET,path=/static_content/swagger-ui.css,type=,length=) (status=200,type=text/css; charset=utf-8,length=143980) 21.630ms (trace=e1e4970d7df5362bf0f3389aac99f7d0,span=6b0a96cb0e2245a7,sampled=0)\n",
      "2023-03-25T18:49:40-0600 [INFO] [api_server:pretrained_classification_service:9] 127.0.0.1:51443 (scheme=http,method=GET,path=/static_content/swagger-initializer.js,type=,length=) (status=304,type=,length=) 8.208ms (trace=79124879a4a0d7e9e1c47ad9a4f66c4c,span=90a6a5f5b9b89c94,sampled=0)\n",
      "2023-03-25T18:49:40-0600 [INFO] [api_server:pretrained_classification_service:6] 127.0.0.1:51441 (scheme=http,method=GET,path=/static_content/index.css,type=,length=) (status=304,type=,length=) 8.617ms (trace=d3364271de63d434305322d5457b0347,span=94e15987319bacf3,sampled=0)\n",
      "2023-03-25T18:49:40-0600 [INFO] [api_server:pretrained_classification_service:10] 127.0.0.1:51442 (scheme=http,method=GET,path=/static_content/swagger-ui-standalone-preset.js,type=,length=) (status=200,type=application/javascript,length=339540) 12.119ms (trace=04f3c7544ddc15ee60a36a9f3cdc18ec,span=065a9e98214ea132,sampled=0)\n",
      "2023-03-25T18:49:40-0600 [INFO] [api_server:pretrained_classification_service:7] 127.0.0.1:51440 (scheme=http,method=GET,path=/static_content/swagger-ui-bundle.js,type=,length=) (status=200,type=application/javascript,length=1096221) 57.658ms (trace=9f218e12e6249b15f3d6a3e84211b916,span=8b93e72b384a2826,sampled=0)\n",
      "2023-03-25T18:49:40-0600 [INFO] [api_server:pretrained_classification_service:7] 127.0.0.1:51440 (scheme=http,method=GET,path=/docs.json,type=,length=) (status=200,type=application/json,length=4656) 9.870ms (trace=3490593ad7a334918fa3b8d16f93e8c0,span=097242f76059edc1,sampled=0)\n",
      "2023-03-25T18:49:40-0600 [INFO] [api_server:pretrained_classification_service:7] 127.0.0.1:51439 (scheme=http,method=GET,path=/static_content/favicon-32x32.png,type=,length=) (status=200,type=image/png,length=1912) 1.901ms (trace=05e17eb8dafaab71d7b3366570cba388,span=64fcf45e7b2f62b3,sampled=0)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve pretrained_classification_service:latest --production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = \"GroNLP/hateBERT\"\n",
    "NUM_LABELS = 2\n",
    "model = (AutoModelForSequenceClassification.from_pretrained(ckpt, num_labels=NUM_LABELS)\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt)\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b23f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-cased\", num_labels=5)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "import bentoml\n",
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
    "\n",
    "bentoml.transformers.save_model(name=\"unmasker\", pipeline=unmasker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec6781f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"Internal Server Error\"}\n"
     ]
    }
   ],
   "source": [
    "#Make an API Request\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url =  'https://xb7e2wbuwj.execute-api.us-east-2.amazonaws.com/' #Endpoint from AWS API Gateway\n",
    "data = {\"data\":\"[5.1, 3.5, 1.4, 0.2]\"} #Lambda function payload\n",
    "\n",
    "response = requests.post(url=url, data=json.dumps(data))\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409e3e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"label\":\"LABEL_0\",\"score\":0.676551342010498}]\n"
     ]
    }
   ],
   "source": [
    "#374806654920.dkr.ecr.us-east-2.amazonaws.com/pretrained_classification:2qgvurwfjojwv6wa\n",
    "#https://runtime.sagemaker.us-east-2.amazonaws.com/endpoints/quickstart-endpoint/invocations\n",
    "import boto3\n",
    "\n",
    "# Create a low-level client representing Amazon SageMaker Runtime\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name=\"us-east-2\")\n",
    "\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account. \n",
    "endpoint_name='pretrained-classification-endpoint'\n",
    "\n",
    "# After you deploy a model into production using SageMaker hosting \n",
    "# services, your client applications use this API to get inferences \n",
    "# from the model hosted at the specified endpoint.\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "                            EndpointName=endpoint_name, \n",
    "                            Body=bytes('{\"text\": \"This is great!\"}', 'utf-8') # Replace with your own data.\n",
    "                            )\n",
    "\n",
    "# Optional - Print the response body and decode it so it is human read-able.\n",
    "print(response['Body'].read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a700dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://hc3gvhv6ha.execute-api.us-east-2.amazonaws.com\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
